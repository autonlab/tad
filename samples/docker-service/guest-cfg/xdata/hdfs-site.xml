<configuration>
  <!-- High Availability -->
  <property>
    <name>dfs.nameservices</name>
    <value>xdata</value>
  </property>
  <property>
    <name>dfs.ha.namenodes.xdata</name>
    <value>xd-nn1.xdata.data-tactics-corp.com_1,xd-nn2.xdata.data-tactics-corp.com_2</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.xdata.xd-nn1.xdata.data-tactics-corp.com_1</name>
    <value>xd-nn1.xdata.data-tactics-corp.com:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.xdata.xd-nn2.xdata.data-tactics-corp.com_2</name>
    <value>xd-nn2.xdata.data-tactics-corp.com:8020</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.xdata.xd-nn1.xdata.data-tactics-corp.com_1</name>
    <value>xd-nn1.xdata.data-tactics-corp.com:50070</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.xdata.xd-nn2.xdata.data-tactics-corp.com_2</name>
    <value>xd-nn2.xdata.data-tactics-corp.com:50070</value>
  </property>
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://xd-jn01.xdata.data-tactics-corp.com:8485;xd-jn02.xdata.data-tactics-corp.com:8485;xd-jn03.xdata.data-tactics-corp.com:8485/xdata</value>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/data1/hadoop/dfs/journal</value>
  </property>
 
  <!-- Zookeeper failover -->
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <!-- Zookeeper failover -->
 
  <!-- Manual Failover -->
  <property>
    <name>dfs.client.failover.proxy.provider.xdata</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>shell(/bin/true)</value>
  </property>
  <!-- Manual Failover -->
 
  <!-- High Availability -->
 
  <property>
     <name>dfs.namenode.name.dir</name>
     <value>file:///data1/hadoop/dfs/nn</value>
     <final>true</final>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>hadoop</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.permissions.enabled</name>
    <value>false</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
<value>file:///data1/hadoop/dfs/dn,file:///data2/hadoop/dfs/dn,file:///data3/hadoop/dfs/dn,file:///data4/hadoop/dfs/dn,file:///data5/hadoop/dfs/dn,file:///data6/hadoop/dfs/dn,file:///data7/hadoop/dfs/dn</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.namenode.replication.min</name>
    <value>3</value>
    <final>true</final>
  </property>
 
  <property>
    <name>dfs.replication.max</name>
    <value>10</value>
    <final>true</final>
  </property>
 
 
  <property>
    <name>mapreduce.client.submit.file.replication</name>
    <value>3</value>
    <final>true</final>
  </property>
 
  <property>
    <name>dfs.hosts</name>
    <value>/etc/hadoop/conf/hosts.include</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>/etc/hadoop/conf/hosts.exclude</value>
    <final>true</final>
  </property>
 
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <!-- Short-Circuit local reads -->
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.streams.cache.size</name>
    <value>1000</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.streams.cache.expiry.ms</name>
    <value>10000</value>
  </property>
  <property>
    <name>dfs.client.file-block-storage-locations.timeout.millis</name>
    <value>10000</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hadoop-hdfs/dn._PORT</value>
  </property>
  <!-- Short-Circuit local reads -->
 
  <!-- Block location tracking -->
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <!-- Block location tracking -->
 
 
  <!-- HBase Additions -->
  <property>
     <name>dfs.datanode.max.transfer.threads</name>
     <value>4096</value>
  </property>
  <!-- HBase Additions -->
</configuration>